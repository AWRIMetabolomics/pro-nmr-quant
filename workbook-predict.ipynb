{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from io import StringIO\n",
    "from datetime import datetime # for report\n",
    "import re\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy import integrate\n",
    "\n",
    "# import utility functions\n",
    "from my_utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "template_path = \"./data/pro_template.csv\"\n",
    "path_samples = \"./data/pro_test_samples/\"\n",
    "fn_to_exclude_ls = [] # list of files to ignore within path_samples. Leave empty if everything is to be included.\n",
    "#manual_calc_path = \"/Users/dteng/Documents/zdata/20220111_DEN_Proline_CombinedData.csv\"\n",
    "lr_results_path = \"./results/lr-results-sample.json\"\n",
    "\n",
    "normxcorr_th = 0.0 # set to this number to filter out multiplets which aren't at least normxcorr_th, i.e. poor fits\n",
    "ref_pk_window = [-0.02, 0.02]\n",
    "ref_pk_tolerance_window = [0,0]\n",
    "multiplets_ls = [[1.9,2.15], \n",
    "                 [2.305, 2.408],\n",
    "                 [3.25, 3.5],\n",
    "                 [4.1, 4.2]]\n",
    "search_region_padding_size = 0.02\n",
    "dept_var = \"auc_target\"\n",
    "conc_dict = {\n",
    "      \"01\":5104,\n",
    "      \"02\":2041.6,\n",
    "      \"03\":1020.8,\n",
    "      \"04\":816.64,\n",
    "      \"05\":510.4,\n",
    "      \"06\":306.24,\n",
    "      \"07\":127.6,\n",
    "      \"08\":51.04,\n",
    "      \"09\":25.52,\n",
    "      \"10\":10.208,\n",
    "      \"11\":0\n",
    "   }\n",
    "\n",
    "fn_out_plot = \"./results/pred_results.html\"\n",
    "fn_out_df = \"./results/pred_results.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== load sample data ==========\n",
    "df_dict = {}\n",
    "for fn in os.listdir(path_samples):\n",
    "    if (\".csv\" in fn) and (fn not in fn_to_exclude_ls):\n",
    "        dt = pd.read_csv(path_samples+\"/\"+fn)\n",
    "        k = fn.replace(\".csv\", \"\")\n",
    "\n",
    "        # adjust ref pk\n",
    "        dt = adjust_to_ref_peak(dt, ref_pk_window, ref_pk_tolerance_window)\n",
    "        df_dict[k] = dt\n",
    "        \n",
    "# load STD template(s)\n",
    "template_df = pd.read_csv(template_path)\n",
    "\n",
    "# load fitted gradient from lr_fitting\n",
    "with open(lr_results_path) as f:\n",
    "    lr_results_dict = json.load(f)\n",
    "\n",
    "# ========== run 1d_std_search ==========\n",
    "results_dict = {}\n",
    "for k in sorted(list(df_dict.keys())):\n",
    "    target_df = df_dict[k]\n",
    "    results_dict[k] = do_1d_std_search(query_df=template_df, \n",
    "                                       target_df=target_df,\n",
    "                                       multiplets_ls=multiplets_ls,\n",
    "                                       search_region_padding_size=search_region_padding_size\n",
    "                                      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done in 0.39s\n"
     ]
    }
   ],
   "source": [
    "t0 = time.perf_counter()\n",
    "\n",
    "# ========== get df_auc ==========\n",
    "df_conc = get_df_auc(template_df, df_dict, results_dict, multiplets_ls)\n",
    "\n",
    "df_conc[\"conc_pred\"] = df_conc[dept_var].values * lr_results_dict[\"multiplet_1\"][\"gradient\"]\n",
    "df_conc[\"conc_pred_lower\"] = df_conc[dept_var].values * lr_results_dict[\"multiplet_1\"][\"gradient_ci\"][0]\n",
    "df_conc[\"conc_pred_upper\"] = df_conc[dept_var].values * lr_results_dict[\"multiplet_1\"][\"gradient_ci\"][1]\n",
    "\n",
    "# some final modifications\n",
    "dt2 = df_conc.loc[(df_conc[\"multiplet\"]==\"multiplet_1\") & (df_conc[\"normxcorr\"]>normxcorr_th)]\n",
    "#dz = pd.merge(d_manual, dt2, on=\"sample_name\", how=\"right\")\n",
    "#temp_arr = dz[\"manual_conc\"] - dz[\"conc_pred\"]\n",
    "#dz[\"conc_error_manual-pred\"] = temp_arr\n",
    "#temp_arr = ((dz[\"manual_conc\"].values - dz[\"conc_pred\"].values)/dz[\"manual_conc\"].values)*100\n",
    "#dz[\"pct_error\"] = temp_arr\n",
    "\n",
    "print(\"Done in %.2fs\" % (time.perf_counter() - t0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done in 8.44s\n"
     ]
    }
   ],
   "source": [
    "# viz plot for visual confirmation/QC\n",
    "t0 = time.time()\n",
    "keys_ls = sorted(list(df_dict.keys()))\n",
    "fig, ax = plt.subplots(nrows=len(keys_ls), # top row for LR results\n",
    "                       ncols=len(multiplets_ls), \n",
    "                       figsize=(30, (len(keys_ls)+1)*4)\n",
    "                      )\n",
    "\n",
    "# viz fit\n",
    "for i in range(len(keys_ls)):\n",
    "    k = keys_ls[i]\n",
    "    \n",
    "    for j in range(len(multiplets_ls)):\n",
    "        mcoords = multiplets_ls[j]\n",
    "        # plot sample (blue)\n",
    "        dt_target = df_dict[k]\n",
    "        dt_target = dt_target.loc[(dt_target[\"ppm\"]>min(mcoords)-search_region_padding_size) & \n",
    "                                  (dt_target[\"ppm\"]<max(mcoords)+search_region_padding_size)].copy()\n",
    "        target_intensity_arr = dt_target[\"intensity\"].values - min(dt_target[\"intensity\"].values)\n",
    "        dt_target[\"intensity\"] = target_intensity_arr\n",
    "\n",
    "        ax[i, j].plot(dt_target.ppm.values, dt_target.intensity.values, c=\"steelblue\")\n",
    "        \n",
    "        # plot fit (red)\n",
    "        # shift ppm\n",
    "        ppm_shift = max(mcoords) - max(results_dict[k][f\"multiplet_{j}\"][\"multiplet_match_ppm\"][0])\n",
    "        multiplet_df = template_df.loc[(template_df[\"ppm\"]>min(mcoords)) & (template_df[\"ppm\"]<max(mcoords))].copy()\n",
    "        new_ppm_arr = multiplet_df.ppm.values - ppm_shift\n",
    "        multiplet_df[\"ppm\"] = new_ppm_arr\n",
    "\n",
    "        # floor spectra\n",
    "        query_intensity_arr = multiplet_df[\"intensity\"].values - min(multiplet_df[\"intensity\"].values)\n",
    "        multiplet_df[\"intensity\"] = query_intensity_arr\n",
    "\n",
    "        # get sf\n",
    "        sf = df_conc.loc[(df_conc[\"multiplet\"]==f\"multiplet_{j}\") & (df_conc[\"sample_name\"]==k)].scaling_factor.values[0]\n",
    "\n",
    "        ax[i, j].plot(multiplet_df.ppm.values, multiplet_df.intensity.values/sf, c=\"indianred\")\n",
    "\n",
    "        # set bg colour\n",
    "        xcorr = max(results_dict[k][f\"multiplet_{j}\"][\"rho_ls\"])\n",
    "        bg_colour = \"#FE9FA5\"\n",
    "        if xcorr > 0.8 and xcorr < 0.95:\n",
    "            bg_colour = \"#FEDA96\"\n",
    "        elif xcorr >= 0.95:\n",
    "            bg_colour = \"#96FEBF\"\n",
    "        ax[i, j].set_facecolor(bg_colour)\n",
    "        ax[i, j].set_title(f\"norm_xcorr={round(xcorr, 3)}\", fontsize=25)\n",
    "        plt.setp(ax[i, j].get_xticklabels(), fontsize=20)\n",
    "        plt.setp(ax[i, j].get_yticklabels(), fontsize=20)\n",
    "        \n",
    "        # yaxis labels with sample names\n",
    "        if j == 0:\n",
    "            ax[i, j].set_ylabel(k.replace(\"20220111_\", \"\").replace(\"20220113_\", \"\"), fontsize=21)\n",
    "\n",
    "plt.subplots_adjust(hspace=0, wspace=0)\n",
    "plt.tight_layout()\n",
    "plt.close()\n",
    "\n",
    "print(\"Done in %.2fs\" % (time.time() - t0))\n",
    "\n",
    "i = StringIO()\n",
    "fig.savefig(i, format=\"svg\")\n",
    "output_svg = i.getvalue().strip().split(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote out to:\n",
      "./results/pred_results.html\n",
      "./results/pred_results.csv\n"
     ]
    }
   ],
   "source": [
    "# resize svg\n",
    "svg_ls = resize_svg(output_svg, resize_coeff=0.5)\n",
    "\n",
    "# prep html form\n",
    "html_contents = [\"<html><head></head><body>\"]\n",
    "\n",
    "html_contents.append(f\"<li>Report generated: {datetime.today().strftime('%Y-%m-%d')}</li>\")\n",
    "html_contents.append(f\"<li>num_samples = {len(keys_ls)}</li>\")\n",
    "html_contents.append(f\"<li>normxcorr threshold = {normxcorr_th}</li>\")\n",
    "html_contents.append(f\"<li>ref peak window = {ref_pk_window}</li>\")\n",
    "html_contents.append(f\"<li>ref peak tolerance window = {ref_pk_tolerance_window}</li>\")\n",
    "html_contents.append(f\"<li>AUC variable = {dept_var}</li>\")\n",
    "html_contents.append(f\"<li>search region padding size (ppm) = {search_region_padding_size}</li>\")\n",
    "html_contents.append(f\"<li>Output csv = {fn_out_df}</li>\")\n",
    "\n",
    "html_contents.append(f\"<h3>LR Params</h3>\")\n",
    "html_contents.append(f\"<li>Intercept = {lr_results_dict['multiplet_1']['intercept']}(ignore this, reported for completeness)</li>\")\n",
    "html_contents.append(f\"<li>Gradient = {lr_results_dict['multiplet_1']['gradient']}, CI = {lr_results_dict['multiplet_1']['gradient_ci']}</li>\")\n",
    "html_contents.append(f\"<li>R^2 = {lr_results_dict['multiplet_1']['rsquared']}</li>\")\n",
    "html_contents.append(f\"<li>Adjusted R^2 = {lr_results_dict['multiplet_1']['rsquared_adj']}</li>\")\n",
    "html_contents.append(\"<hr>\")\n",
    "for line in output_svg:\n",
    "    html_contents.append(line)\n",
    "html_contents.append(\"</body></html>\")\n",
    "\n",
    "# write out\n",
    "with open(fn_out_plot, \"w\") as f:\n",
    "    for line in html_contents:\n",
    "        f.write(line)\n",
    "\n",
    "dt2.to_csv(fn_out_df, index=False)\n",
    "\n",
    "print(f\"Wrote out to:\\n{fn_out_plot}\\n{fn_out_df}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
